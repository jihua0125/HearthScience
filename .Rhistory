player.info.np
run.np <- player.info.np[which(team.np$solution==1),8]
run.np
run.np <- mean(player.info.np[which(team.np$solution==1),8])
run.up
run.np
run.np <- sum(player.info.np[which(team.np$solution==1),8])
run.np
player.info.np[which(team.np$solution==1),1]
sum(player.info.np[which(team.np$solution==1),8])/9
player.info
fit.w  %>% filter(teamID=="OAK") %>%
ggplot(aes(yearID,.resid)) + geom_point() + geom_smooth() +
scale_x_continuous(breaks=1985:2014) + xlab("Year") +
title("Oakland")
fit.w  %>% filter(teamID=="OAK") %>%
ggplot(aes(yearID,.resid)) + geom_point() + geom_smooth() +
scale_x_continuous(breaks=1985:2014) + xlab("Year") +
labs(title="Oakland")
fit.w  %>% filter(teamID=="BOS") %>%
ggplot(aes(yearID,.resid)) + geom_point() + geom_smooth() +
scale_x_continuous(breaks=1985:2014) + xlab("Year") +
labs(title="Boston")
Teams %>% filter(yearID==2002) %>%
# get all the required terms
mutate(BB = BB/G, singles = (H-X2B-X3B-HR)/G, XB= (X2B+X3B)/G, HR = HR/G, SB = SB/G) %>%
select(teamID, BB, singles, XB, HR, SB) %>%
# provide ranks for each term in descending order
mutate(BB.rank = rank(-BB, ties.method="min")) %>%
mutate(singles.rank = rank(-singles, ties.method="min")) %>%
mutate(extra.rank = rank(-XB, ties.method="min")) %>%
mutate(HR.rank = rank(-HR, ties.method="min")) %>%
mutate(SB.rank = rank(-SB, ties.method="min")) %>%
# show result for OAK
filter(teamID=="OAK")
names(Batting)
0.4348+c(-1,1)*1.96*0.0731
0.6591+c(-1,1)*1.96*0.0715
exp(-0.8176)
exp(-0.4086)
exp(-0.282)
log(0.589)/0.755
log(0.589)/0.75f4
log(0.589)/0.754
exp(-0.702)
log(0.333)/0.754
exp(-1.46)
(0.018/0.181)^2
901.58-899.56
(0.295/.208)^2
exp(-0.401)
exp(-0.401+c(-1,1)*1.96*0.283)
exp(-0.401-0.795)
exp(0.057)
exp(-0.004)
899.56-888.45
43/277
X <- select(train_set , pixel0:pixel783) %>% as.matrix()
thrid_row <- X[3,]
tenth_column <- X[,10]
X_1 <- X[1,]
X_2 <- X[2,]
X_253 <- X[253,]
sqrt(sum((X_1-X_2)^2))
sqrt(sum((X_1-X_253)^2))
sqrt( crossprod(X_1-X_2) )
sqrt( crossprod(X_1-X_253) )
d <- dist(X)
class(d)
as.matrix(d)[1,2]
as.matrix(d)[1,253]
image(as.matrix(d))
ggplot(train_set) +
geom_point(aes(X_1, X_2, fill=label), pch=21, cex=5)
image(as.matrix(dist(t(X))))
glm_fit <- glm(y~.,data = select(train_set, y, X_1, X_2) )
f_hat <- predict(glm_fit, newdata = test_set,
type = "response")
tab <- table(pred=round(f_hat), truth=test_set$y)
confusionMatrix(tab)$tab
confusionMatrix(tab)$overall["Accuracy"]
X_1
y
train_set[153,]$y
1-5/83
0.94*0.85
1-10/73
0.799*0.863
exp(-0.347)
0.049^2/(0.287^2)
log(0.287)+c(-1,1)*1.96*sqrt(0.0291)
exp(-1.582,-0.914)
exp(c(-1.582,-0.914))
0.218/0.287
(0.857/0.2457)^2
4958.4-4947.18
exp(-0.2517)
-0.2517+c(-1,1)*1.96*0.0935
exp(c(-0.435,0.0684))
exp(c(-0.435,-0.0684))
4978.75-4975.59
4978.75-4970.99
4978.75-4972.24
4978.75-4977.64
exp(-0.0165)
exp(-0.3555)
exp(-0.5238)
exp(-0.5238-0.3555+0.857)
exp(0.875)
log(0.189)/exp(40*-0.0165)
exp(-3.22)
exp(40*-0.0165-0.2517-0.3555)
0.04^0.282
exp(40*-0.0165-0.2517-0.3555-0.5238+0.857)
0.04^0.393
?dnorm
control <- trainControl(method='cv', number=2, p=.5)
control
?trainControl
temp_filename <- tempfile() ## creaate tempory file name
temp_object <- 1:5 ## create an R object
save(temp_object, file=temp_filename) ## save the r object to file
rm(temp_object) ## remove object
load(temp_filename) ## load object from file
3207.5-3085.2
3207.5-3164.4
24.123+21.3109
ï¼5.7417+0.9895+3.9920+0.3119
-5.7417+0.9895+3.9920+0.3119
.3367+.4692
.3367+.7072
3090.1-3082.6
27.0347+0.2605
.3187+.6965
-1.02+c(-1,1)*sqrt(1.144)
27.0347+0.122+2.9926
2.2607-1.02
chisq.test(13,4)
?chisq.test
pchisq(13,4)
1-pchisq(13,4)
1-pchisq(7.6,6)
7.1665-6.6252
0.7844+0.3048
0.7844-0.04475
16.3406+7.844
16.3406+7.844-1.0321+3.048
15.65-22.28
1-pchisq(11,6)
1-pchisq(0.3,2)
1-pchisq(10.7,4)
578-539.2
1-pchisq(3.8,2)
1-pchisq(38.8,4)
3.3502*3-0.2039*3
install.packages("mvtnorm")
install.packages("pROC")
url <- "https://raw.githubusercontent.com/datasciencelabs/data/master/hand-written-digits-train.csv"
if(!exists("digits")) digits <- read_csv(url)
dat <- digits %>% filter(label%in%c(2,7))
dat <- mutate(dat, label =  as.character(label)) %>%
mutate(y = ifelse(label=="2",0,1 ))
dat
row_column <- expand.grid(row=1:28, col=1:28)
ind1 <- which(row_column$col <= 14 & row_column$row <=14)
ind2 <- which(row_column$col > 14 & row_column$row > 14)
ind1
row_column
ind <- c(ind1,ind2)
X <- as.matrix(dat[,-1])
X1 <- rowSums(X[,ind1])/rowSums(X)
X2 <- rowSums(X[,ind2])/rowSums(X)
dat <- mutate(dat, X_1 = X1, X_2 = X2)
X
dim(X)
dim(ind1)
length(ind1)
length(ind2)
dim(dat)
head(dat)
option(digit=5)
options(digit=5)
url <- "https://raw.githubusercontent.com/datasciencelabs/data/master/hand-written-digits-test.csv"
original_test<- read_csv(url)
install.packages("XQuartz")
original_dat <- mutate(original_dat, label = as.factor(label))
url <- "https://raw.githubusercontent.com/datasciencelabs/data/master/hand-written-digits-train.csv"
original_dat <- read_csv(url)
original_dat <- mutate(original_dat, label = as.factor(label))
url <- "https://raw.githubusercontent.com/datasciencelabs/data/master/hand-written-digits-test.csv"
original_test<- read_csv(url)
View(original_test)
install.packages("XQuartz")
install.packages("XQuartz")
install.packages("XQuartz")
sqrt(383)
383*3
80.7-43.8
1-pchisq(36.9,8)
2.202+8.824
.169-.05198
.169+.2276
0.11702*12
0.169*12
9.953/(9.953+.6647)
12*0.11702
12*0.169
9.953+0.6647
9..953/10.6177
9.953/10.6177
library(readr)
library(dplyr)
library(tidyr)
library(ggplot2)
theme_set(theme_bw(base_size = 16))
plotit <- function(dat, i, n=sqrt(ncol(dat)-1)){
dat <- slice(dat,i)
tmp <-  expand.grid(Row=1:n, Column=1:n) %>%
mutate(id=i, label=dat$label,
value = unlist(dat[,-1]))
tmp%>%ggplot(aes(Row, Column, fill=value)) +
geom_raster() +
scale_y_reverse() +
scale_fill_gradient(low="white", high="black") +
ggtitle(tmp$label[1])
}
url <- "https://raw.githubusercontent.com/datasciencelabs/data/master/hand-written-digits-train.csv"
original_dat <- read_csv(url)
original_dat <- mutate(original_dat, label = as.factor(label))
url <- "https://raw.githubusercontent.com/datasciencelabs/data/master/hand-written-digits-test.csv"
original_test<- read_csv(url)
X <- sample_n(original_dat,200) %>%
arrange(label)
d <- dist(as.matrix(X[,-1]))
image(as.matrix(d))
plot(hclust(d),labels=as.character(X$label))
tmp <- slice(original_dat,1:100)
?gsub
tmp <- tmp %>% mutate(obs = 1:nrow(tmp))    # track which one is which obs
names(tmp) <- gsub("pixel","",names(tmp))    # takes pixel out and only left the numbers
tmp <- tmp %>% gather(feature, value, `0`:`783`)
tmp <- tmp %>% mutate(feature = as.numeric(feature))
tmp <- tmp %>% mutate(row = feature%%28, col =floor(feature/28))  # divide by 28 tells the col and row (residual)
tmp <- tmp %>% mutate(row = floor(row/4), col = floor(col/4))
tmp <- tmp %>% group_by(obs, row, col)
tmp <- tmp %>% summarize(label = label[1], value = mean(value))
tmp <- tmp %>% ungroup
?gather
names(original_Dat)
names(original_dat)
head(temp)
head(tmp)
tmp <- tmp %>%  mutate(feature = sprintf("X_%02d_%02d",col,row))  # order
head(tmp)
tmp <- tmp %>%  select(-row, -col)
tmp <- tmp %>% group_by(obs) %>% spread(feature, value) %>% ungroup %>% select(-obs)
head(tmp)
compress <- function(tbl, n=4){
names(tbl) <- gsub("pixel","",names(tbl))
tbl %>% mutate(obs = 1:nrow(tbl)) %>%
gather(feature, value, `0`:`783`) %>%
mutate(feature = as.numeric(feature)) %>%
mutate(row = feature%%28, col =floor(feature/28)) %>%
mutate(row = floor(row/n), col = floor(col/n)) %>%
group_by(obs, row, col)  %>%
summarize(label = label[1], value = mean(value)) %>%
ungroup %>%
mutate(feature = sprintf("X_%02d_%02d",col,row)) %>%
select(-row, -col) %>%
group_by(obs) %>% spread(feature, value) %>%
ungroup %>%
select(-obs)
}
dat <- compress(original_dat)
library(caret)
set.seed(1)
inTrain <- createDataPartition(y = dat$label,
p=0.9)$Resample
X <- dat %>% select(-label) %>% slice(inTrain) %>% as.matrix
column_means <- colMeans(X)
plot(table(round(column_means)))
keep_columns <- which(column_means>10)
head(dat)
keep_columns <- which(column_means>10)
train_set <- slice(dat, inTrain) %>% select(label, keep_columns+1)
test_set <- slice(dat, -inTrain) %>% select(label, keep_columns+1)
head(train_set)
X <- sample_n(train_set,200) %>%
arrange(label)
d <- dist(as.matrix(X[,-1]))
image(as.matrix(d))
plot(hclust(d),labels=as.character(X$label))
tmp = sample_n(train_set,5000)
control <- trainControl(method='cv', number=20)
res <- train(label ~ .,
data = tmp,
method = "knn",
trControl = control,
tuneGrid=data.frame(k=seq(1,15,2)),
metric="Accuracy")
plot(res)
fit <- knn3(label~., train_set, k=3)
pred <- predict(fit, newdata = test_set, type="class")
tab <- table(pred, test_set$label)
confusionMatrix(tab)
original_test <- mutate(original_test, label=NA)
test <- compress(original_test)
test <- test %>% select(label, keep_columns+1)
pred <- predict(fit, newdata = test, type="class")
i=11
pred[i]
plotit(original_test,i)
res <- data.frame(ImageId=1:nrow(test),Label=as.character(pred))
write.csv(res, file="test.csv", row.names=FALSE)
install.packages("matrixStats")
install.packages("Biobase")
install.packages("GSE5859")
library(devtolls)
library(devtools)
install_github("genomicsclass/GSE5859""")
install_github("genomicsclass/GSE5859")
library(Biobase)
install.packages("Biobase")
library(knitr)
opts_chunk$set(fig.path=paste0("figure/", sub("(.*).Rmd","\\1",basename(knitr:::knit_concord$get('infile'))), "-"))
library(dplyr)
library(ggplot2)
theme_set(theme_bw(base_size = 16))
library(rafalib)
set.seed(1)
n <- 100
lim <- c(60,78)
X <- MASS::mvrnorm(n,
c(69,69),
matrix(c(9,9*0.92,9*0.92,9*1),2,2))
mypar(1,1)
plot(X, xlim=lim, ylim=lim)
points(X[1:2,], col="red", pch=16)
lines(X[1:2,],col="red")
d=dist(X)
as.matrix(d)[1,2]
X <- sweep(X, 2, colMeans(X))
Z <- X[,1]
mypar(1,2)
plot(dist(X), dist(Z))
abline(0,1)
Z <-X[,2]
plot(dist(X), dist(Z))
abline(0,1)
Z <- X[,1]
mypar(1,1)
plot(dist(X)/sqrt(2), dist(Z))
abline(0,1)
cor(dist(X), dist(Z))
library(rafalib)
set.seed(1)
n <- 100
lim <- c(60,78)
X <- MASS::mvrnorm(n,
c(69,69),
matrix(c(9,9*0.92,9*0.92,9*1),2,2))
mypar(1,1)
plot(X, xlim=lim, ylim=lim)
points(X[1:2,], col="red", pch=16)
lines(X[1:2,],col="red")
d=dist(X)
as.matrix(d)[1,2]
X <- sweep(X, 2, colMeans(X))
d=dist(X)
as.matrix(d)[1,2]
X
library(rafalib)
set.seed(1)
n <- 100
lim <- c(60,78)
X <- MASS::mvrnorm(n,
c(69,69),
matrix(c(9,9*0.92,9*0.92,9*1),2,2))
mypar(1,1)
plot(X, xlim=lim, ylim=lim)
points(X[1:2,], col="red", pch=16)
lines(X[1:2,],col="red")
X
X <- sweep(X, 2, colMeans(X))
X
Z <- X[,1]
mypar(1,2)
plot(dist(X), dist(Z))
abline(0,1)
Z <-X[,2]
plot(dist(X), dist(Z))
abline(0,1)
Z <- X[,1]
mypar(1,1)
plot(dist(X)/sqrt(2), dist(Z))
abline(0,1)
cor(dist(X), dist(Z))
avg <- rowMeans(X) ##or (X[,1] + X[,2])/2
diff <- X[,2] - X[,1]
Z  <- cbind( avg, diff)
mypar(1,2)
lim <- lim - 69
plot(X, xlim=lim, ylim=lim)
points(X[1:2,], col="red", pch=16)
lines(X[1:2,], col="red")
plot(Z, xlim=lim, ylim=lim)
points(Z[1:2,], col="red", pch=16)
lines(Z[1:2,], col="red")
getwd
getwd()
library(dplyr)
library(tidyr)
library(ggplot2)
setwd("~/Desktop/2016/HearthScience")
basic<-tbl_df(read.csv("Basic.csv",sep="\t"))
brm<-tbl_df(read.csv("blackrock_mountain.csv",sep="\t"))
gng<-tbl_df(read.csv("Goblins_Gnomes.csv",sep="\t"))
classic<-tbl_df(read.csv("Classic.csv",sep="\t"))
naxx<-tbl_df(read.csv("Naxxramas.csv",sep="\t"))
pro<-tbl_df(read.csv("promotion.csv",sep="\t"))
tgt<-tbl_df(read.csv("The_grand_tournament.csv",sep="\t"))
tle<-tbl_df(read.csv("The_league_of_explorers.csv",sep="\t"))
load("/Users/Yinnan/Desktop/2016/HearthScience/final_data.RData")
View(final_data)
library(tidyr)
x <- load("/Users/Yinnan/Desktop/2016/dataset/rawvotingdata13.rdata")
dim(x)
load("/Users/Yinnan/Desktop/2016/dataset/rawvotingdata13.rdata")
load("/Users/Yinnan/Desktop/2016/dataset/rawvotingdata13.rdata")
TEMP <- load("/Users/Yinnan/Desktop/2016/dataset/rawvotingdata13.rdata")
RM(X)
rm(x)
rm(TEMP)
x <- load("/Users/Yinnan/Desktop/2016/dataset/rawvotingdata13.rdata")
rm(x)
load("/Users/Yinnan/Desktop/2016/dataset/rawvotingdata13.rdata")
dim(x)
rm(x)
temp <- load("/Users/Yinnan/Desktop/2016/dataset/rawvotingdata13.rdata")
data <- get(temp)
rm(temp)
rm(data)
rm(x)
data <- load("/Users/Yinnan/Desktop/2016/dataset/rawvotingdata13.rdata")
x <- get(data)
votes <- tbl_df(x)
rm(x)
dim(votes)
head(votes)
votes %>% unique(vote)
library(dplyr)
unique(votes$vote)
votes %>% group_by(vote) %>% summarize(n=n)
votes %>% group_by(vote) %>% summarize(n)
table(votes$vote)
votes %>% group_by(vote) %>% summarize(n=n(vote))
votes %>% group_by(vote) %>% summarize(n)
table(votes$vote)
typeof(votes$vote)
votes <- votes %>% filter(vote %in% c(1,2,3))
dim(votes)
table(votes$vote)
head(votes)
install.packages("countrycode")
library(countrycode)
install.packages("countrycode")
install.packages("countrycode")
library(countrycode)
library(countrycode)
library(countrycode)
library(countrycode)
install.packages("countrycode")
install.packages("countrycode")
library(countrycode)
countrycode("Tuvalu","coutry.name","cown")
countrycode("DZA","iso3c","cowc")
countrycode("Tuvalu","country.name","cown")
countrycode("Tonga","country.name","cown")
countrycode("Kiribati","country.name","cown")
dim(votes)
cowcodes <- votes$ccode
country <- countrycode(cowcodes,"cown","country.name")
votes <- votes %>% bind_cols(country)
library(dplyr)
library(dplyr)
votes <- votes %>% bind_cols(country)
country <- as.data.frame(countrycode(cowcodes,"cown","country.name"))
votes <- votes %>% bind_cols(country)
dim(votes)
head(votes)
countrycode("United States","country.name","cown")
countrycode("Mexico","country.name","cown")
names(vote)
names(votes)
names(votes)[5]
names(votes)[5]<-"country"
head(votes)
library(tidyr)
mapping <- c("United States"="USA",
"United Kingdom"="UK",
"Korea, Republic of"="South Korea",
"Lao People's Democratic Republic"="Laos",
"Yemen People's Republic"="South Yemen",
"Saint Vincent and the Grenadines"="Saint Vincent",
"Congo"="Congo Republic")
votes <- votes %>% mutate(country = plyr::revalue(country, mapping)) %>%
separate(country, into = c("country", "extra"), sep=",", fill="right")
head(votes)
library(readr)
url <- "https://raw.githubusercontent.com/datasciencelabs/data/master/un-resolutions-descriptions.csv"
descriptions <- read_csv(url, col_types = list(date = col_date("%m/%d/%y")))
descriptions <- read_csv(url, col_types = list(date = col_date("%m/%d/%y")))
